{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"nlpdemystified-vectorization.ipynb","private_outputs":true,"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Natural Language Processing Demystified | Simple Vectorization\nhttps://nlpdemystified.org<br>\nhttps://github.com/futuremojo/nlp-demystified","metadata":{"id":"F50G99nH112P"}},{"cell_type":"markdown","source":"### spaCy upgrade and package installation.","metadata":{"id":"t9x6fL6L3zsb"}},{"cell_type":"markdown","source":"At the time this notebook was created, spaCy had newer releases but Colab was still using version 2.x by default. So the first step is to upgrade spaCy and download a statisical language model.\n<br><br>\n**IMPORTANT**<br>\nIf you're running this in the cloud rather than using a local Jupyter server on your machine, then the notebook will **timeout** after a period of inactivity. If that happens and you don't reconnect in time, you will need to upgrade spaCy again and reinstall the requisite statistical packages.\n<br><br>\nRefer to this link on how to run Colab notebooks locally on your machine to avoid this issue:<br>\nhttps://research.google.com/colaboratory/local-runtimes.html","metadata":{"id":"88uW0zDh4BkP"}},{"cell_type":"code","source":"!pip install -U spacy==3.*\n!python -m spacy download en_core_web_sm\n!python -m spacy info","metadata":{"id":"THBGyQba4Bcm"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Basic Bag-of-Words (BOW)\n\nCourse module for this demo: https://www.nlpdemystified.org/course/basic-bag-of-words","metadata":{"id":"t81VT9JboTzt"}},{"cell_type":"code","source":"import spacy\n\nfrom scipy import spatial\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"id":"u_EAof8njfHz","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:00.709362Z","iopub.execute_input":"2025-03-07T03:20:00.709697Z","iopub.status.idle":"2025-03-07T03:20:08.394914Z","shell.execute_reply.started":"2025-03-07T03:20:00.709672Z","shell.execute_reply":"2025-03-07T03:20:08.393920Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Plain frequency BOW","metadata":{"id":"b1IVdG29wyJ7"}},{"cell_type":"code","source":"# A corpus of sentences.\ncorpus = [\n  \"Red Bull drops hint on F1 engine.\",\n  \"Honda exits F1, leaving F1 partner Red Bull.\",\n  \"Hamilton eyes record eighth F1 title.\",\n  \"Aston Martin announces sponsor.\"\n]","metadata":{"id":"2fwfWQDVyJpY","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:08.396176Z","iopub.execute_input":"2025-03-07T03:20:08.396624Z","iopub.status.idle":"2025-03-07T03:20:08.400623Z","shell.execute_reply.started":"2025-03-07T03:20:08.396593Z","shell.execute_reply":"2025-03-07T03:20:08.399785Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"We want to build a basic bag-of-words (BOW) representation of our corpus. Based on what you now know from the lesson, you can probably do this from scratch using dictionaries and lists (and maybe that's a good exercise). Fortunately, there are robust libraries which make it easy.\n\nWe can use the scikit-learn **CountVectorizer** which takes a collection of text documents and creates a matrix of token counts:<br>\nhttps://scikit-learn.org/stable/index.html<br>\nhttps://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n\n\n","metadata":{"id":"ILvS020Zzm6F"}},{"cell_type":"code","source":"vectorizer = CountVectorizer()","metadata":{"id":"IRhJPxbHwuj_","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:08.402276Z","iopub.execute_input":"2025-03-07T03:20:08.402602Z","iopub.status.idle":"2025-03-07T03:20:08.419375Z","shell.execute_reply.started":"2025-03-07T03:20:08.402577Z","shell.execute_reply":"2025-03-07T03:20:08.418314Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"The *fit_transform* method does two things:\n1. It learns a vocabulary dictionary from the corpus.\n2. It returns a matrix where each row represents a document and each column represents a token (i.e. term).<br>\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform\n","metadata":{"id":"iAphZMVPBX9P"}},{"cell_type":"code","source":"bow = vectorizer.fit_transform(corpus)","metadata":{"id":"-5wi4_C7BAWv","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:08.420444Z","iopub.execute_input":"2025-03-07T03:20:08.420767Z","iopub.status.idle":"2025-03-07T03:20:08.436223Z","shell.execute_reply.started":"2025-03-07T03:20:08.420741Z","shell.execute_reply":"2025-03-07T03:20:08.435316Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"We can take a look at the features and vocabulary dictionary. Notice the **CountVectorizer** took care of tokenization for us. It also removed punctuation and lower-cased everything.","metadata":{"id":"z3Bp1XNcF1FQ"}},{"cell_type":"code","source":"# View features (tokens).\nprint(vectorizer.get_feature_names_out())\n\n# View vocabulary dictionary.\nvectorizer.vocabulary_","metadata":{"id":"fQbqvLgVF8B7","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:08.975138Z","iopub.execute_input":"2025-03-07T03:20:08.975464Z","iopub.status.idle":"2025-03-07T03:20:08.983783Z","shell.execute_reply.started":"2025-03-07T03:20:08.975438Z","shell.execute_reply":"2025-03-07T03:20:08.982766Z"}},"outputs":[{"name":"stdout","text":"['announces' 'aston' 'bull' 'drops' 'eighth' 'engine' 'exits' 'eyes' 'f1'\n 'hamilton' 'hint' 'honda' 'leaving' 'martin' 'on' 'partner' 'record'\n 'red' 'sponsor' 'title']\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'red': 17,\n 'bull': 2,\n 'drops': 3,\n 'hint': 10,\n 'on': 14,\n 'f1': 8,\n 'engine': 5,\n 'honda': 11,\n 'exits': 6,\n 'leaving': 12,\n 'partner': 15,\n 'hamilton': 9,\n 'eyes': 7,\n 'record': 16,\n 'eighth': 4,\n 'title': 19,\n 'aston': 1,\n 'martin': 13,\n 'announces': 0,\n 'sponsor': 18}"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Specifically, the **CountVectorizer** generates a sparse matrix using an efficient, compressed representation. The sparse matrix object includes a number of useful methods:\nhttps://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html","metadata":{"id":"7dmNUkZeExam"}},{"cell_type":"code","source":"print(type(bow))","metadata":{"id":"Lug2-xnAExsb","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:11.814226Z","iopub.execute_input":"2025-03-07T03:20:11.814567Z","iopub.status.idle":"2025-03-07T03:20:11.819180Z","shell.execute_reply.started":"2025-03-07T03:20:11.814541Z","shell.execute_reply":"2025-03-07T03:20:11.818113Z"}},"outputs":[{"name":"stdout","text":"<class 'scipy.sparse._csr.csr_matrix'>\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"If we look at the raw structure, we'll see tuples where the first element represents the document, and the second element represents a token ID. It's then followed by a count of that token. So in the second document (index 1), token 8 (\"f1\") occurs twice.","metadata":{"id":"3bywJ0XnGKPQ"}},{"cell_type":"code","source":"print(bow)","metadata":{"id":"At6Gt4bsEx2D","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:12.498820Z","iopub.execute_input":"2025-03-07T03:20:12.499164Z","iopub.status.idle":"2025-03-07T03:20:12.504494Z","shell.execute_reply.started":"2025-03-07T03:20:12.499138Z","shell.execute_reply":"2025-03-07T03:20:12.503453Z"}},"outputs":[{"name":"stdout","text":"  (0, 17)\t1\n  (0, 2)\t1\n  (0, 3)\t1\n  (0, 10)\t1\n  (0, 14)\t1\n  (0, 8)\t1\n  (0, 5)\t1\n  (1, 17)\t1\n  (1, 2)\t1\n  (1, 8)\t2\n  (1, 11)\t1\n  (1, 6)\t1\n  (1, 12)\t1\n  (1, 15)\t1\n  (2, 8)\t1\n  (2, 9)\t1\n  (2, 7)\t1\n  (2, 16)\t1\n  (2, 4)\t1\n  (2, 19)\t1\n  (3, 1)\t1\n  (3, 13)\t1\n  (3, 0)\t1\n  (3, 18)\t1\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Before we explore further, we want to make a few modifications.\n1. What if we want to use another tokenizer like spaCy's?\n2. Instead of frequency, what if we want to have a binary BOW?\n","metadata":{"id":"mv1N1Io2EyAb"}},{"cell_type":"markdown","source":"## Binary BOW with custom tokenizer","metadata":{"id":"KRgIHkzUVJtk"}},{"cell_type":"markdown","source":"**CountVectorizer** supports using a custom tokenizer. For every document, it will call your tokenizer and expect a list of tokens returned. We'll create a simple callback below which has spaCy tokenize and filter tokens, and then return them.","metadata":{"id":"tof1PBgqEy1D"}},{"cell_type":"code","source":"# As usual, we start by importing spaCy and loading a statistical model.\nnlp = spacy.load('en_core_web_sm')\n\n# Create a tokenizer callback using spaCy under the hood. Here, we tokenize\n# the passed-in text and return the tokens, filtering out punctuation.\ndef spacy_tokenizer(doc):\n  return [t.text for t in nlp(doc) if not t.is_punct]\n","metadata":{"id":"AcCLawrWEzC7","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:16.795503Z","iopub.execute_input":"2025-03-07T03:20:16.795832Z","iopub.status.idle":"2025-03-07T03:20:17.742033Z","shell.execute_reply.started":"2025-03-07T03:20:16.795806Z","shell.execute_reply":"2025-03-07T03:20:17.740999Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"This time, we instantiate **CountVectorizer** with our custom tokenizer (*spacy_tokenizer*), turn off case-folding, and also set the *binary* parameter to *True* so we simply get 1s and 0s marking token presence rather than token frequency.","metadata":{"id":"drEe1Lv_OScv"}},{"cell_type":"code","source":"vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True)\nbow = vectorizer.fit_transform(corpus)","metadata":{"id":"1YREyWzaA-rT","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:17.743249Z","iopub.execute_input":"2025-03-07T03:20:17.743517Z","iopub.status.idle":"2025-03-07T03:20:17.801434Z","shell.execute_reply.started":"2025-03-07T03:20:17.743493Z","shell.execute_reply":"2025-03-07T03:20:17.800453Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n  warnings.warn(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Looking at the resulting feature names and vocabulary dictionary, we can see our *spacy_tokenizer* being used. If you're not convinced, you can remove the punctuation filtering in our tokenizer and rerun the code.","metadata":{"id":"5jDKQkZUOysa"}},{"cell_type":"code","source":"print(vectorizer.get_feature_names_out())\nvectorizer.vocabulary_","metadata":{"id":"4x6RBqTGq302","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:20.123768Z","iopub.execute_input":"2025-03-07T03:20:20.124165Z","iopub.status.idle":"2025-03-07T03:20:20.131657Z","shell.execute_reply.started":"2025-03-07T03:20:20.124135Z","shell.execute_reply":"2025-03-07T03:20:20.130597Z"}},"outputs":[{"name":"stdout","text":"['Aston' 'Bull' 'F1' 'Hamilton' 'Honda' 'Martin' 'Red' 'announces' 'drops'\n 'eighth' 'engine' 'exits' 'eyes' 'hint' 'leaving' 'on' 'partner' 'record'\n 'sponsor' 'title']\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'Red': 6,\n 'Bull': 1,\n 'drops': 8,\n 'hint': 13,\n 'on': 15,\n 'F1': 2,\n 'engine': 10,\n 'Honda': 4,\n 'exits': 11,\n 'leaving': 14,\n 'partner': 16,\n 'Hamilton': 3,\n 'eyes': 12,\n 'record': 17,\n 'eighth': 9,\n 'title': 19,\n 'Aston': 0,\n 'Martin': 5,\n 'announces': 7,\n 'sponsor': 18}"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"To get a dense array representation of our sparse matrix, use *toarray*.<br>\nhttps://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.toarray.html#scipy.sparse.csr_matrix.toarray\n\nWe can also index and slice into the sparse matrix.","metadata":{"id":"hFpQbdA-R3FI"}},{"cell_type":"code","source":"print('A dense representation like we saw in the slides.')\nprint(bow.toarray())\nprint()\nprint('Indexing and slicing.')\nprint(bow[0])\nprint()\nprint(bow[0:2])","metadata":{"id":"2yGr36aP9GCr","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:22.449716Z","iopub.execute_input":"2025-03-07T03:20:22.450101Z","iopub.status.idle":"2025-03-07T03:20:22.457907Z","shell.execute_reply.started":"2025-03-07T03:20:22.450068Z","shell.execute_reply":"2025-03-07T03:20:22.456792Z"}},"outputs":[{"name":"stdout","text":"A dense representation like we saw in the slides.\n[[0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0]\n [0 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0]\n [0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1]\n [1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0]]\n\nIndexing and slicing.\n  (0, 6)\t1\n  (0, 1)\t1\n  (0, 8)\t1\n  (0, 13)\t1\n  (0, 15)\t1\n  (0, 2)\t1\n  (0, 10)\t1\n\n  (0, 6)\t1\n  (0, 1)\t1\n  (0, 8)\t1\n  (0, 13)\t1\n  (0, 15)\t1\n  (0, 2)\t1\n  (0, 10)\t1\n  (1, 6)\t1\n  (1, 1)\t1\n  (1, 2)\t1\n  (1, 4)\t1\n  (1, 11)\t1\n  (1, 14)\t1\n  (1, 16)\t1\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Cosine Similarity","metadata":{"id":"XF0NVhdEUR1r"}},{"cell_type":"markdown","source":"Writing your own cosine similarity function is straight-forward using numpy (left as an exercise). There are multiple ways to calculate it using scipy.\n<br><br>\nOne way is using the **spatial** package, which is a collection of spatial algorithms and data structures. It has a method to calculate cosine *distance*. To get the cosine *similarity*, we have to substract the distance from 1.<br>\nhttps://docs.scipy.org/doc/scipy/reference/spatial.html<br>\nhttps://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine","metadata":{"id":"leI1VuDVVP4W"}},{"cell_type":"code","source":"# The cosine method expects array_like inputs, so we need to generate\n# arrays from our sparse matrix.\ndoc1_vs_doc2 = 1 - spatial.distance.cosine(bow[0].toarray()[0], bow[1].toarray()[0])\ndoc1_vs_doc3 = 1 - spatial.distance.cosine(bow[0].toarray()[0], bow[2].toarray()[0])\ndoc1_vs_doc4 = 1 - spatial.distance.cosine(bow[0].toarray()[0], bow[3].toarray()[0])\n\nprint(corpus)\n\nprint(f\"Doc 1 vs Doc 2: {doc1_vs_doc2}\")\nprint(f\"Doc 1 vs Doc 3: {doc1_vs_doc3}\")\nprint(f\"Doc 1 vs Doc 4: {doc1_vs_doc4}\")","metadata":{"id":"kOQQ50IgXQfH","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:25.784113Z","iopub.execute_input":"2025-03-07T03:20:25.784608Z","iopub.status.idle":"2025-03-07T03:20:25.796153Z","shell.execute_reply.started":"2025-03-07T03:20:25.784563Z","shell.execute_reply":"2025-03-07T03:20:25.794906Z"}},"outputs":[{"name":"stdout","text":"['Red Bull drops hint on F1 engine.', 'Honda exits F1, leaving F1 partner Red Bull.', 'Hamilton eyes record eighth F1 title.', 'Aston Martin announces sponsor.']\nDoc 1 vs Doc 2: 0.4285714285714286\nDoc 1 vs Doc 3: 0.15430334996209194\nDoc 1 vs Doc 4: 0.0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Another approach is using scikit-learn's *cosine_similarity* which computes the metric between multiple vectors. Here, we pass it our BOW and get a matrix of cosine similarities between each document.<br>\nhttps://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html","metadata":{"id":"6SRDwr2gYD04"}},{"cell_type":"code","source":"# cosine_similarity can take either array-likes or sparse matrices.\nprint(cosine_similarity(bow))","metadata":{"id":"WwwP8-jtchSI","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:28.056754Z","iopub.execute_input":"2025-03-07T03:20:28.057151Z","iopub.status.idle":"2025-03-07T03:20:28.063628Z","shell.execute_reply.started":"2025-03-07T03:20:28.057122Z","shell.execute_reply":"2025-03-07T03:20:28.062436Z"}},"outputs":[{"name":"stdout","text":"[[1.         0.42857143 0.15430335 0.        ]\n [0.42857143 1.         0.15430335 0.        ]\n [0.15430335 0.15430335 1.         0.        ]\n [0.         0.         0.         1.        ]]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## N-grams","metadata":{"id":"I96W6qDVdDnY"}},{"cell_type":"markdown","source":"**CountVectorizer** includes an *ngram_range* parameter to generate different n-grams. n_gram range is specified using a minimum and maximum range. By default, n_gram range is set to (1, 1) which generates unigrams. Setting it to (1, 2) generates both unigrams and bigrams.","metadata":{"id":"D3E_hN5Ddyae"}},{"cell_type":"code","source":"vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True, ngram_range=(1,2))\nbigrams = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names_out())\nprint('Number of features: {}'.format(len(vectorizer.get_feature_names_out())))\nprint(vectorizer.vocabulary_)","metadata":{"id":"OZooyyRleHXe","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:39.579491Z","iopub.execute_input":"2025-03-07T03:20:39.579810Z","iopub.status.idle":"2025-03-07T03:20:39.619584Z","shell.execute_reply.started":"2025-03-07T03:20:39.579783Z","shell.execute_reply":"2025-03-07T03:20:39.618464Z"}},"outputs":[{"name":"stdout","text":"['Aston' 'Aston Martin' 'Bull' 'Bull drops' 'F1' 'F1 engine' 'F1 leaving'\n 'F1 partner' 'F1 title' 'Hamilton' 'Hamilton eyes' 'Honda' 'Honda exits'\n 'Martin' 'Martin announces' 'Red' 'Red Bull' 'announces'\n 'announces sponsor' 'drops' 'drops hint' 'eighth' 'eighth F1' 'engine'\n 'exits' 'exits F1' 'eyes' 'eyes record' 'hint' 'hint on' 'leaving'\n 'leaving F1' 'on' 'on F1' 'partner' 'partner Red' 'record'\n 'record eighth' 'sponsor' 'title']\nNumber of features: 40\n{'Red': 15, 'Bull': 2, 'drops': 19, 'hint': 28, 'on': 32, 'F1': 4, 'engine': 23, 'Red Bull': 16, 'Bull drops': 3, 'drops hint': 20, 'hint on': 29, 'on F1': 33, 'F1 engine': 5, 'Honda': 11, 'exits': 24, 'leaving': 30, 'partner': 34, 'Honda exits': 12, 'exits F1': 25, 'F1 leaving': 6, 'leaving F1': 31, 'F1 partner': 7, 'partner Red': 35, 'Hamilton': 9, 'eyes': 26, 'record': 36, 'eighth': 21, 'title': 39, 'Hamilton eyes': 10, 'eyes record': 27, 'record eighth': 37, 'eighth F1': 22, 'F1 title': 8, 'Aston': 0, 'Martin': 13, 'announces': 17, 'sponsor': 38, 'Aston Martin': 1, 'Martin announces': 14, 'announces sponsor': 18}\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Setting n_gram range to (2, 2) generates only bigrams.\nvectorizer = CountVectorizer(tokenizer=spacy_tokenizer, lowercase=False, binary=True, ngram_range=(2,2))\nbigrams = vectorizer.fit_transform(corpus)\nprint(vectorizer.get_feature_names_out())\nprint(vectorizer.vocabulary_)","metadata":{"id":"Hvtmi3negc0G","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:39.749859Z","iopub.execute_input":"2025-03-07T03:20:39.750215Z","iopub.status.idle":"2025-03-07T03:20:39.787000Z","shell.execute_reply.started":"2025-03-07T03:20:39.750188Z","shell.execute_reply":"2025-03-07T03:20:39.786094Z"}},"outputs":[{"name":"stdout","text":"['Aston Martin' 'Bull drops' 'F1 engine' 'F1 leaving' 'F1 partner'\n 'F1 title' 'Hamilton eyes' 'Honda exits' 'Martin announces' 'Red Bull'\n 'announces sponsor' 'drops hint' 'eighth F1' 'exits F1' 'eyes record'\n 'hint on' 'leaving F1' 'on F1' 'partner Red' 'record eighth']\n{'Red Bull': 9, 'Bull drops': 1, 'drops hint': 11, 'hint on': 15, 'on F1': 17, 'F1 engine': 2, 'Honda exits': 7, 'exits F1': 13, 'F1 leaving': 3, 'leaving F1': 16, 'F1 partner': 4, 'partner Red': 18, 'Hamilton eyes': 6, 'eyes record': 14, 'record eighth': 19, 'eighth F1': 12, 'F1 title': 5, 'Aston Martin': 0, 'Martin announces': 8, 'announces sponsor': 10}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Basic Bag-of-Words Exercises","metadata":{"id":"j7e40ZAKhQmm"}},{"cell_type":"code","source":"#\n# EXERCISE: Create a spacy_tokenizer callback which takes a string and returns\n# a list of tokens (each token's text) with punctuation filtered out.\n#\ncorpus = [\n  \"Students use their GPS-enabled cellphones to take birdview photographs of a land in order to find specific danger points such as rubbish heaps.\",\n  \"Teenagers are enthusiastic about taking aerial photograph in order to study their neighbourhood.\",\n  \"Aerial photography is a great way to identify terrestrial features that aren’t visible from the ground level, such as lake contours or river paths.\",\n  \"During the early days of digital SLRs, Canon was pretty much the undisputed leader in CMOS image sensor technology.\",\n  \"Syrian President Bashar al-Assad tells the US it will 'pay the price' if it strikes against Syria.\"\n]\n\nnlp = spacy.load('en_core_web_sm')\n\ndef spacy_tokenizer(doc):\n    doc = nlp(doc)\n    return [token.text for token in doc if not token.is_punct]\n ","metadata":{"id":"dbdMO0bZjROn","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:41.524435Z","iopub.execute_input":"2025-03-07T03:20:41.524743Z","iopub.status.idle":"2025-03-07T03:20:42.385664Z","shell.execute_reply.started":"2025-03-07T03:20:41.524719Z","shell.execute_reply":"2025-03-07T03:20:42.384822Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"#\n# EXERCISE: Initialize a CountVectorizer object and set it to use\n# your spacy_tokenizer with lower-casing off and to create a binary BOW.\n#\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Instantiate a CountVectorizer object called 'vectorizer'.\nvectorizer = CountVectorizer(tokenizer=spacy_tokenizer, binary=True, lowercase=False)\n\n# Create a binary BOW from the corpus using your CountVectorizer.\nbinary_bow = vectorizer.fit_transform(corpus)\n","metadata":{"id":"UjBJUUpcBWp2","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:42.386901Z","iopub.execute_input":"2025-03-07T03:20:42.387298Z","iopub.status.idle":"2025-03-07T03:20:42.446157Z","shell.execute_reply.started":"2025-03-07T03:20:42.387265Z","shell.execute_reply":"2025-03-07T03:20:42.445356Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Print feature names (unique tokens)\nprint(vectorizer.get_feature_names_out())\n\n# Print the binary bag-of-words matrix\nprint(binary_bow.toarray())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:42.447647Z","iopub.execute_input":"2025-03-07T03:20:42.447909Z","iopub.status.idle":"2025-03-07T03:20:42.453530Z","shell.execute_reply.started":"2025-03-07T03:20:42.447878Z","shell.execute_reply":"2025-03-07T03:20:42.452618Z"}},"outputs":[{"name":"stdout","text":"['Aerial' 'Assad' 'Bashar' 'CMOS' 'Canon' 'During' 'GPS' 'President'\n 'SLRs' 'Students' 'Syria' 'Syrian' 'Teenagers' 'US' 'a' 'about' 'aerial'\n 'against' 'al' 'are' 'as' 'birdview' 'cellphones' 'contours' 'danger'\n 'days' 'digital' 'early' 'enabled' 'enthusiastic' 'features' 'find'\n 'from' 'great' 'ground' 'heaps' 'identify' 'if' 'image' 'in' 'is' 'it'\n 'lake' 'land' 'leader' 'level' 'much' 'neighbourhood' 'n’t' 'of' 'or'\n 'order' 'paths' 'pay' 'photograph' 'photographs' 'photography' 'points'\n 'pretty' 'price' 'river' 'rubbish' 'sensor' 'specific' 'strikes' 'study'\n 'such' 'take' 'taking' 'technology' 'tells' 'terrestrial' 'that' 'the'\n 'their' 'to' 'undisputed' 'use' 'visible' 'was' 'way' 'will']\n[[0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1\n  0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0\n  0 0 1 1 0 1 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n  0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n  0 0 1 1 0 0 0 0 0 0]\n [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0\n  1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1\n  1 1 0 1 0 0 1 0 1 0]\n [0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0\n  0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0\n  0 1 0 0 1 0 0 1 0 0]\n [0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0\n  0 1 0 0 0 0 0 0 0 1]]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"vectorizer.vocabulary_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:42.454545Z","iopub.execute_input":"2025-03-07T03:20:42.454808Z","iopub.status.idle":"2025-03-07T03:20:42.472500Z","shell.execute_reply.started":"2025-03-07T03:20:42.454775Z","shell.execute_reply":"2025-03-07T03:20:42.471485Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'Students': 9,\n 'use': 77,\n 'their': 74,\n 'GPS': 6,\n 'enabled': 28,\n 'cellphones': 22,\n 'to': 75,\n 'take': 67,\n 'birdview': 21,\n 'photographs': 55,\n 'of': 49,\n 'a': 14,\n 'land': 43,\n 'in': 39,\n 'order': 51,\n 'find': 31,\n 'specific': 63,\n 'danger': 24,\n 'points': 57,\n 'such': 66,\n 'as': 20,\n 'rubbish': 61,\n 'heaps': 35,\n 'Teenagers': 12,\n 'are': 19,\n 'enthusiastic': 29,\n 'about': 15,\n 'taking': 68,\n 'aerial': 16,\n 'photograph': 54,\n 'study': 65,\n 'neighbourhood': 47,\n 'Aerial': 0,\n 'photography': 56,\n 'is': 40,\n 'great': 33,\n 'way': 80,\n 'identify': 36,\n 'terrestrial': 71,\n 'features': 30,\n 'that': 72,\n 'n’t': 48,\n 'visible': 78,\n 'from': 32,\n 'the': 73,\n 'ground': 34,\n 'level': 45,\n 'lake': 42,\n 'contours': 23,\n 'or': 50,\n 'river': 60,\n 'paths': 52,\n 'During': 5,\n 'early': 27,\n 'days': 25,\n 'digital': 26,\n 'SLRs': 8,\n 'Canon': 4,\n 'was': 79,\n 'pretty': 58,\n 'much': 46,\n 'undisputed': 76,\n 'leader': 44,\n 'CMOS': 3,\n 'image': 38,\n 'sensor': 62,\n 'technology': 69,\n 'Syrian': 11,\n 'President': 7,\n 'Bashar': 2,\n 'al': 18,\n 'Assad': 1,\n 'tells': 70,\n 'US': 13,\n 'it': 41,\n 'will': 81,\n 'pay': 53,\n 'price': 59,\n 'if': 37,\n 'strikes': 64,\n 'against': 17,\n 'Syria': 10}"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"#\n# The string below is a whole paragraph. We want to create another\n# binary BOW but using the vocabulary of our *current* CountVectorizer. This means\n# that words in this paragraph which AREN'T already in the vocabulary won't be\n# represented. This is to illustrate how BOW can't handle out-of-vocabulary words\n# unless you rebuild your whole vocabulary. Still, we'll see that if there's\n# enough overlapping vocabulary, some similarity can still be picked up.\n#\n# Note that we call 'transform' only instead of 'fit_transform' because the\n# fit step (i.e. vocabulary build) is already done and we don't want to re-fit here.\n#\ns = [\"Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\"]\nnew_bow = vectorizer.transform(s)\n\n#\n# EXERCISE: using the pairwise cosine_similarity method from sklearn,\n# calculate the similarities between each document from the corpus against\n# this new document (new_bow). HINT: You can pass two parameters to\n# cosine_similarity in this case. See the docs:\n# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n#\n# Which document is the most similar? Which is the least similar? Do the results make sense\n# based on what you see?\n#\n\nsimilarities = cosine_similarity(binary_bow, new_bow)\nprint(similarities)","metadata":{"id":"os3tPj5nmRLw","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:48.774354Z","iopub.execute_input":"2025-03-07T03:20:48.774680Z","iopub.status.idle":"2025-03-07T03:20:48.805749Z","shell.execute_reply.started":"2025-03-07T03:20:48.774653Z","shell.execute_reply":"2025-03-07T03:20:48.804901Z"}},"outputs":[{"name":"stdout","text":"[[0.69565217]\n [0.40482045]\n [0.29192018]\n [0.19658927]\n [0.0521286 ]]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Print similarity scores\nprint(\"Cosine Similarity Scores:\")\nfor i, score in enumerate(similarities):\n    print(f\"Document {i}: {score[0]:.4f}\")\n\n# Identify the most and least similar documents\nmost_similar_idx = similarities.argmax()\nleast_similar_idx = similarities.argmin()\n\nprint(f\"\\nMost similar document: Document {most_similar_idx}\")\nprint(f\"Least similar document: Document {least_similar_idx}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:48.959194Z","iopub.execute_input":"2025-03-07T03:20:48.959526Z","iopub.status.idle":"2025-03-07T03:20:48.966603Z","shell.execute_reply.started":"2025-03-07T03:20:48.959499Z","shell.execute_reply":"2025-03-07T03:20:48.965715Z"}},"outputs":[{"name":"stdout","text":"Cosine Similarity Scores:\nDocument 0: 0.6957\nDocument 1: 0.4048\nDocument 2: 0.2919\nDocument 3: 0.1966\nDocument 4: 0.0521\n\nMost similar document: Document 0\nLeast similar document: Document 4\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"#\n# EXERCISE: Implement your own cosine similarity method using numpy.\n# It should take two numpy arrays and output the similarity metric.\n# HINTS:\n# https://numpy.org/doc/stable/reference/generated/numpy.dot.html\n# https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n#\n# Verify the similarity between the first document in the corpus and the\n# paragraph is the same as the one you got from using pairwise cosine_similarity.\n#\nimport numpy as np\ndef cos_sim(a, b):\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n# Get binary BoW representations for corpus and new document\nnew_bow_array = new_bow.toarray().flatten()  # Convert sparse matrix to dense array\nfirst_doc_array = binary_bow[0].toarray().flatten()\n\n# Compute cosine similarity using our custom function\ncustom_similarity = cos_sim(first_doc_array, new_bow_array)\n\n# Compute cosine similarity using sklearn for verification\nsklearn_similarity = cosine_similarity(binary_bow[0], new_bow)[0][0]\n\n# Print both similarity scores\nprint(f\"Custom Cosine Similarity: {custom_similarity:.4f}\")\nprint(f\"Sklearn Cosine Similarity: {sklearn_similarity:.4f}\")\n\n# Verify if results match\nassert np.isclose(custom_similarity, sklearn_similarity), \"Mismatch in similarity scores!\"\nprint(\"✅ The custom implementation matches sklearn's output!\")\n","metadata":{"id":"eXThYmDiwMmR","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:20:49.614832Z","iopub.execute_input":"2025-03-07T03:20:49.615213Z","iopub.status.idle":"2025-03-07T03:20:49.631901Z","shell.execute_reply.started":"2025-03-07T03:20:49.615182Z","shell.execute_reply":"2025-03-07T03:20:49.631034Z"}},"outputs":[{"name":"stdout","text":"Custom Cosine Similarity: 0.6957\nSklearn Cosine Similarity: 0.6957\n✅ The custom implementation matches sklearn's output!\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"#\n# EXERCISE: In spacy_tokenizer, instead of returning the plain text,\n# return the lemma_ attribute instead. How do the cosine similarity\n# results differ? What if you filter out stop words as well?\n#\n# Custom tokenizer returning lemmas instead of raw tokens\ndef spacy_tokenizer(text):\n    doc = nlp(text)\n    return [token.lemma_ for token in doc if not token.is_punct]  # Removing punctuation\n\n# Initialize CountVectorizer using the custom tokenizer\nvectorizer = CountVectorizer(tokenizer=spacy_tokenizer, binary=True)\n\n# Fit and transform the corpus\nbinary_bow = vectorizer.fit_transform(corpus)\n\n# Transform the new document\nnew_bow = vectorizer.transform(s)\n\n# Compute cosine similarity\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nsimilarities = cosine_similarity(binary_bow, new_bow)\n\n# Print results\nprint(\"Cosine Similarity Scores (Lemmatized):\")\nfor i, score in enumerate(similarities):\n    print(f\"Document {i}: {score[0]:.4f}\")\n\ndef spacy_tokenizer(text):\n    doc = nlp(text)\n    return [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n\nvectorizer = CountVectorizer(tokenizer=spacy_tokenizer, binary=True)\nbinary_bow = vectorizer.fit_transform(corpus)\nnew_bow = vectorizer.transform(s)\nsimilarities = cosine_similarity(binary_bow, new_bow)\n\nprint(\"Cosine Similarity Scores (Lemmatized + Stopwords Removed):\")\nfor i, score in enumerate(similarities):\n    print(f\"Document {i}: {score[0]:.4f}\")\n","metadata":{"id":"ghlqn6l-dal4","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:21:01.772931Z","iopub.execute_input":"2025-03-07T03:21:01.773330Z","iopub.status.idle":"2025-03-07T03:21:01.899213Z","shell.execute_reply.started":"2025-03-07T03:21:01.773301Z","shell.execute_reply":"2025-03-07T03:21:01.898258Z"}},"outputs":[{"name":"stdout","text":"Cosine Similarity Scores (Lemmatized):\nDocument 0: 0.6957\nDocument 1: 0.4627\nDocument 2: 0.3405\nDocument 3: 0.2457\nDocument 4: 0.0521\nCosine Similarity Scores (Lemmatized + Stopwords Removed):\nDocument 0: 0.5729\nDocument 1: 0.2942\nDocument 2: 0.1482\nDocument 3: 0.0801\nDocument 4: 0.0000\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import spacy\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load spaCy model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Corpus of texts\ncorpus = [\n    \"Students use their GPS-enabled cellphones to take birdview photographs of a land in order to find specific danger points such as rubbish heaps.\",\n    \"Teenagers are enthusiastic about taking aerial photograph in order to study their neighbourhood.\",\n    \"Aerial photography is a great way to identify terrestrial features that aren’t visible from the ground level, such as lake contours or river paths.\",\n    \"During the early days of digital SLRs, Canon was pretty much the undisputed leader in CMOS image sensor technology.\",\n    \"Syrian President Bashar al-Assad tells the US it will 'pay the price' if it strikes against Syria.\"\n]\n\n# New document for comparison\nnew_doc = [\"Teenagers take aerial shots of their neighbourhood using digital cameras sitting in old bottles which are launched via kites - a common toy for children living in the favelas. They then use GPS-enabled smartphones to take pictures of specific danger points - such as rubbish heaps, which can become a breeding ground for mosquitoes carrying dengue fever.\"]\n\n# Tokenizer functions\ndef basic_tokenizer(text):\n    \"\"\"Returns raw tokens (without preprocessing)\"\"\"\n    doc = nlp(text)\n    return [token.text for token in doc if not token.is_punct]\n\ndef lemma_tokenizer(text):\n    \"\"\"Returns lemmatized tokens\"\"\"\n    doc = nlp(text)\n    return [token.lemma_ for token in doc if not token.is_punct]\n\ndef lemma_no_stop_tokenizer(text):\n    \"\"\"Returns lemmatized tokens with stopwords removed\"\"\"\n    doc = nlp(text)\n    return [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n\n# Compute similarity with different preprocessing\nvectorizers = {\n    \"Raw Tokens\": CountVectorizer(tokenizer=basic_tokenizer, binary=True),\n    \"Lemmatized\": CountVectorizer(tokenizer=lemma_tokenizer, binary=True),\n    \"Lemmatized + No Stopwords\": CountVectorizer(tokenizer=lemma_no_stop_tokenizer, binary=True)\n}\n\n# Store similarity results\nsimilarity_scores = {}\n\nfor key, vectorizer in vectorizers.items():\n    bow_corpus = vectorizer.fit_transform(corpus)\n    bow_new = vectorizer.transform(new_doc)\n    similarities = cosine_similarity(bow_corpus, bow_new).flatten()\n    similarity_scores[key] = similarities\n\n# Plot the similarity scores\nlabels = [f\"Doc {i+1}\" for i in range(len(corpus))]\nx = np.arange(len(corpus))  # Document indices\nwidth = 0.25  # Bar width\n\nfig, ax = plt.subplots(figsize=(10, 5))\n\n# Plot bars for each method\nax.bar(x - width, similarity_scores[\"Raw Tokens\"], width, label=\"Raw Tokens\")\nax.bar(x, similarity_scores[\"Lemmatized\"], width, label=\"Lemmatized\")\nax.bar(x + width, similarity_scores[\"Lemmatized + No Stopwords\"], width, label=\"Lemmatized + No Stopwords\")\n\n# Labels and title\nax.set_xlabel(\"Documents\")\nax.set_ylabel(\"Cosine Similarity\")\nax.set_title(\"Cosine Similarity Scores for Different Preprocessing Methods\")\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:21:04.373795Z","iopub.execute_input":"2025-03-07T03:21:04.374177Z","iopub.status.idle":"2025-03-07T03:21:05.648953Z","shell.execute_reply.started":"2025-03-07T03:21:04.374145Z","shell.execute_reply":"2025-03-07T03:21:05.647952Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"# TF-IDF\n\nCourse module for this demo: https://www.nlpdemystified.org/course/tf-idf","metadata":{"id":"CnC_i4oH2ARW"}},{"cell_type":"markdown","source":"**NOTE: If the notebook timed out, you may need to re-upgrade spaCy and re-install the language model as follows:**","metadata":{"id":"Xb7W_O_FS3H6"}},{"cell_type":"code","source":"!pip install -U spacy==3.*\n!python -m spacy download en_core_web_sm\n!python -m spacy info","metadata":{"id":"rRtp9F8KS5QE"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import spacy\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"id":"CMwv39AfP7Ti","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:21:13.413101Z","iopub.execute_input":"2025-03-07T03:21:13.413481Z","iopub.status.idle":"2025-03-07T03:21:13.551699Z","shell.execute_reply.started":"2025-03-07T03:21:13.413451Z","shell.execute_reply":"2025-03-07T03:21:13.550646Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## Fetching datasets","metadata":{"id":"QmcTBtSx-XqZ"}},{"cell_type":"markdown","source":"This time around, rather than using a short toy corpus, let's use a larger dataset. scikit-learn has a **datasets** module with utilties to load datasets of our own as well as fetch popular reference datasets online.<br>\nhttps://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n<br><br>\nWe'll use the **20 newsgroups** dataset, which is a collection of 18,000 newsgroup posts across 20 topics.<br>\nhttps://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset\n<br><br>\nList of datasets available:<br>\nhttps://scikit-learn.org/stable/datasets.html#datasets","metadata":{"id":"WYkq3i7_-qhQ"}},{"cell_type":"markdown","source":"The **datasets** module includes fetchers for each dataset in scikit-learn. For our purposes, we'll fetch only the posts from the *sci.space* topic, and skip on headers, footers, and quoting of other posts.<br>\nhttps://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups\n<br><br>\nBy default, the fetcher retrieves the *training* subset of the data only. If you don't know what that means, it'll become clear later in the course when we discuss modelling. For now, it doesn't matter for our purposes.","metadata":{"id":"UYjxqxVBBINV"}},{"cell_type":"code","source":"corpus = fetch_20newsgroups(categories=['sci.space'],\n                            remove=('headers', 'footers', 'quotes'))","metadata":{"id":"T9to6gQNCGiN","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:21:21.284553Z","iopub.execute_input":"2025-03-07T03:21:21.284878Z","iopub.status.idle":"2025-03-07T03:21:44.979519Z","shell.execute_reply.started":"2025-03-07T03:21:21.284853Z","shell.execute_reply":"2025-03-07T03:21:44.978689Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"We get back a **Bunch** container object containing the data as well as other information.<br>\nhttps://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html\n<br><br>\nThe actual posts are accessed through the *data* attribute and is a list of strings, each one representing a post.","metadata":{"id":"W989GHQxDvTW"}},{"cell_type":"code","source":"print(type(corpus))","metadata":{"id":"POGdVmdIDuCK","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:21:44.980717Z","iopub.execute_input":"2025-03-07T03:21:44.981012Z","iopub.status.idle":"2025-03-07T03:21:44.985553Z","shell.execute_reply.started":"2025-03-07T03:21:44.980985Z","shell.execute_reply":"2025-03-07T03:21:44.984734Z"}},"outputs":[{"name":"stdout","text":"<class 'sklearn.utils._bunch.Bunch'>\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Number of posts in our dataset.\nlen(corpus.data)","metadata":{"id":"q6AgmbL0ES9I","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:21:50.044381Z","iopub.execute_input":"2025-03-07T03:21:50.044716Z","iopub.status.idle":"2025-03-07T03:21:50.050747Z","shell.execute_reply.started":"2025-03-07T03:21:50.044686Z","shell.execute_reply":"2025-03-07T03:21:50.049756Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"593"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# View first two posts.\ncorpus.data[:2]","metadata":{"id":"qAjM4uNDEXGf","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:21:54.064499Z","iopub.execute_input":"2025-03-07T03:21:54.064812Z","iopub.status.idle":"2025-03-07T03:21:54.070098Z","shell.execute_reply.started":"2025-03-07T03:21:54.064787Z","shell.execute_reply":"2025-03-07T03:21:54.069208Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"[\"\\nAny lunar satellite needs fuel to do regular orbit corrections, and when\\nits fuel runs out it will crash within months.  The orbits of the Apollo\\nmotherships changed noticeably during lunar missions lasting only a few\\ndays.  It is *possible* that there are stable orbits here and there --\\nthe Moon's gravitational field is poorly mapped -- but we know of none.\\n\\nPerturbations from Sun and Earth are relatively minor issues at low\\naltitudes.  The big problem is that the Moon's own gravitational field\\nis quite lumpy due to the irregular distribution of mass within the Moon.\",\n '\\nGlad to see Griffin is spending his time on engineering rather than on\\nritual purification of the language.  Pity he got stuck with the turkey\\nrather than one of the sensible options.']"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"## Creating TF-IDF features","metadata":{"id":"FH99M6cxCpsz"}},{"cell_type":"code","source":"# Like before, if we want to use spaCy's tokenizer, we need\n# to create a callback. Remember to upgrade spaCy if you need\n# to (refer to beginnning of file for commentary and instructions).\nnlp = spacy.load('en_core_web_sm')\n\n# We don't need named-entity recognition nor dependency parsing for\n# this so these components are disabled. This will speed up the\n# pipeline. We do need part-of-speech tagging however.\nunwanted_pipes = [\"ner\", \"parser\"]\n\n# For this exercise, we'll remove punctuation and spaces (which\n# includes newlines), filter for tokens consisting of alphabetic\n# characters, and return the lemma (which require POS tagging).\ndef spacy_tokenizer(doc):\n  with nlp.disable_pipes(*unwanted_pipes):\n    return [t.lemma_ for t in nlp(doc) if \\\n            not t.is_punct and \\\n            not t.is_space and \\\n            t.is_alpha]","metadata":{"id":"vtnQX-wWDhGh","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:23:11.117657Z","iopub.execute_input":"2025-03-07T03:23:11.118006Z","iopub.status.idle":"2025-03-07T03:23:11.807578Z","shell.execute_reply.started":"2025-03-07T03:23:11.117976Z","shell.execute_reply":"2025-03-07T03:23:11.806792Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"Like the classes to create raw frequency and binary bag-of-words vectors, scikit-learn includes a similar class called **TfidfVectorizer** to create TF-IDF vectors from a corpus.<br>\nhttps://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n<br><br>\nThe usage pattern is similar in that we call *fit_transform* on the corpus which generates the vocabulary dictionary (fit step), and generates the TF-IDF vectors (transform step).","metadata":{"id":"il-0gY9LEiNv"}},{"cell_type":"code","source":"%%time\n# Use the default settings of TfidfVectorizer.\nvectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\nfeatures = vectorizer.fit_transform(corpus.data)","metadata":{"id":"Shj6BS0BN6FU","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:23:17.485197Z","iopub.execute_input":"2025-03-07T03:23:17.485537Z","iopub.status.idle":"2025-03-07T03:23:31.523211Z","shell.execute_reply.started":"2025-03-07T03:23:17.485510Z","shell.execute_reply":"2025-03-07T03:23:31.522013Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 14.2 s, sys: 217 ms, total: 14.4 s\nWall time: 14 s\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# The number of unique tokens.\nprint(len(vectorizer.get_feature_names_out()))","metadata":{"id":"CZ9w4gh9sobB","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:23:31.524412Z","iopub.execute_input":"2025-03-07T03:23:31.524700Z","iopub.status.idle":"2025-03-07T03:23:31.535542Z","shell.execute_reply.started":"2025-03-07T03:23:31.524667Z","shell.execute_reply":"2025-03-07T03:23:31.534452Z"}},"outputs":[{"name":"stdout","text":"9440\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# The dimensions of our feature matrix. X rows (documents) by Y columns (tokens).\nprint(features.shape)","metadata":{"id":"6CxmKlPcNRLk","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:24:27.428868Z","iopub.execute_input":"2025-03-07T03:24:27.429268Z","iopub.status.idle":"2025-03-07T03:24:27.433654Z","shell.execute_reply.started":"2025-03-07T03:24:27.429238Z","shell.execute_reply":"2025-03-07T03:24:27.432530Z"}},"outputs":[{"name":"stdout","text":"(593, 9440)\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# What the encoding of the first document looks like in sparse format.\nprint(features[0])","metadata":{"id":"yJwnU8PZNdHU","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:24:28.304558Z","iopub.execute_input":"2025-03-07T03:24:28.304909Z","iopub.status.idle":"2025-03-07T03:24:28.310309Z","shell.execute_reply.started":"2025-03-07T03:24:28.304877Z","shell.execute_reply":"2025-03-07T03:24:28.309352Z"}},"outputs":[{"name":"stdout","text":"  (0, 5064)\t0.10452754121963853\n  (0, 2351)\t0.12747025764625855\n  (0, 4340)\t0.15331700873692364\n  (0, 2459)\t0.10862435105627101\n  (0, 4916)\t0.17102715751031994\n  (0, 6702)\t0.09940033595823265\n  (0, 5982)\t0.10183554382071024\n  (0, 6514)\t0.08455482269873241\n  (0, 896)\t0.0892999596249832\n  (0, 316)\t0.1109487112663238\n  (0, 4896)\t0.08247641364333849\n  (0, 628)\t0.051044670776703174\n  (0, 4368)\t0.10270174012167517\n  (0, 5274)\t0.13259746290766442\n  (0, 6908)\t0.12524708704889775\n  (0, 2494)\t0.07376562213268434\n  (0, 8105)\t0.09513204666042695\n  (0, 3287)\t0.051874685324429695\n  (0, 6181)\t0.1390186329543497\n  (0, 5652)\t0.11219531673533985\n  (0, 4589)\t0.06321728493925476\n  (0, 9158)\t0.06158004812009137\n  (0, 1141)\t0.048918909156680825\n  (0, 5023)\t0.12320196834845284\n  (0, 6354)\t0.15331700873692364\n  :\t:\n  (0, 1344)\t0.09036471134545682\n  (0, 5403)\t0.17102715751031994\n  (0, 451)\t0.10452754121963853\n  (0, 5790)\t0.0991335109087398\n  (0, 8368)\t0.20402991671500817\n  (0, 5377)\t0.10099775257415368\n  (0, 9288)\t0.19295422430071502\n  (0, 1901)\t0.13560685996352737\n  (0, 9251)\t0.059876060572569896\n  (0, 4372)\t0.07654889960067542\n  (0, 5938)\t0.06437012757347277\n  (0, 7214)\t0.09717716536087184\n  (0, 4381)\t0.07522603925785983\n  (0, 9214)\t0.07158981085158692\n  (0, 371)\t0.10544208975368659\n  (0, 1846)\t0.13560685996352737\n  (0, 5882)\t0.21555560387140033\n  (0, 6885)\t0.13560685996352737\n  (0, 2372)\t0.04343313069714861\n  (0, 8491)\t0.06551548062794398\n  (0, 3300)\t0.1988006719164653\n  (0, 5546)\t0.07463181843364929\n  (0, 7281)\t0.08827780957141772\n  (0, 4918)\t0.17756754701430466\n  (0, 426)\t0.07007152202826399\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"As we mentioned in the slides, there are TF-IDF variations out there and scikit-learn, among other things, adds **smoothing** (adds a one to the numerator and denominator in the IDF component), and normalizes by default. These can be disabled if desired using the *smooth_idf* and *norm* parameters respectively. See here for more information:<br>\nhttps://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n","metadata":{"id":"Vp7VTwYzONlt"}},{"cell_type":"markdown","source":"## Querying the data","metadata":{"id":"ylKLM-IMOwbJ"}},{"cell_type":"markdown","source":"The similarity measuring techniques we learned previously can be used here in the same way. In effect, we can query our data using this sequence:\n1. *Transform* our query using the same vocabulary from our *fit* step on our corpus.\n2. Calculate the pairwise cosine similarities between each document in our corpus and our query.\n3. Sort them in descending order by score.","metadata":{"id":"h8oTtCg0QB71"}},{"cell_type":"code","source":"# Transform the query into a TF-IDF vector.\nquery = [\"lunar orbit\"]\nquery_tfidf = vectorizer.transform(query)","metadata":{"id":"qNjEUzqlP6Oy","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:26:41.102652Z","iopub.execute_input":"2025-03-07T03:26:41.103037Z","iopub.status.idle":"2025-03-07T03:26:41.113074Z","shell.execute_reply.started":"2025-03-07T03:26:41.103003Z","shell.execute_reply":"2025-03-07T03:26:41.112089Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# Calculate the cosine similarities between the query and each document.\n# We're calling flatten() here becaue cosine_similarity returns a list\n# of lists and we just want a single list.\ncosine_similarities = cosine_similarity(features, query_tfidf).flatten()","metadata":{"id":"jEfdfkmpP8Tv","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:26:46.846609Z","iopub.execute_input":"2025-03-07T03:26:46.846915Z","iopub.status.idle":"2025-03-07T03:26:46.853116Z","shell.execute_reply.started":"2025-03-07T03:26:46.846891Z","shell.execute_reply":"2025-03-07T03:26:46.852186Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"Now that we have our list of cosine similarities, we can use this utility function to return the indices of the top k documents with the highest cosine similarities.","metadata":{"id":"skuSFhLxXOMC"}},{"cell_type":"code","source":"import numpy as np\n\n# numpy's argsort() method returns a list of *indices* that\n# would sort an array:\n# https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\n#\n# The sort is ascending, but we want the largest k cosine_similarites\n# at the bottom of the sort. So we negate k, and get the last k\n# entries of the indices list in reverse order. There are faster\n# ways to do this using things like argpartition but this is\n# more succinct.\ndef top_k(arr, k):\n  kth_largest = (k + 1) * -1\n  return np.argsort(arr)[:kth_largest:-1]","metadata":{"id":"H0PvqRDpUSYO","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:30:55.934238Z","iopub.execute_input":"2025-03-07T03:30:55.934592Z","iopub.status.idle":"2025-03-07T03:30:55.939172Z","shell.execute_reply.started":"2025-03-07T03:30:55.934561Z","shell.execute_reply":"2025-03-07T03:30:55.938087Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# So for our query above, these are the top five documents.\ntop_related_indices = top_k(cosine_similarities, 5)\nprint(top_related_indices)","metadata":{"id":"zFYpEldVUaAG","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:30:56.200511Z","iopub.execute_input":"2025-03-07T03:30:56.200812Z","iopub.status.idle":"2025-03-07T03:30:56.206060Z","shell.execute_reply.started":"2025-03-07T03:30:56.200790Z","shell.execute_reply":"2025-03-07T03:30:56.204975Z"}},"outputs":[{"name":"stdout","text":"[249 108   0 312 509]\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# Let's take a look at their respective cosine similarities.\nprint(cosine_similarities[top_related_indices])","metadata":{"id":"4e86P3bQR1ZS","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:30:57.731811Z","iopub.execute_input":"2025-03-07T03:30:57.732206Z","iopub.status.idle":"2025-03-07T03:30:57.737444Z","shell.execute_reply.started":"2025-03-07T03:30:57.732173Z","shell.execute_reply":"2025-03-07T03:30:57.736424Z"}},"outputs":[{"name":"stdout","text":"[0.47855355 0.4292246  0.2736328  0.19486489 0.19125175]\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"# Top match.\nprint(corpus.data[top_related_indices[0]])","metadata":{"id":"kzdyTptURiTQ","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:31:02.960483Z","iopub.execute_input":"2025-03-07T03:31:02.960821Z","iopub.status.idle":"2025-03-07T03:31:02.966127Z","shell.execute_reply.started":"2025-03-07T03:31:02.960792Z","shell.execute_reply":"2025-03-07T03:31:02.965017Z"}},"outputs":[{"name":"stdout","text":"\nActually, Hiten wasn't originally intended to go into lunar orbit at all,\nso it indeed didn't have much fuel on hand.  The lunar-orbit mission was\nan afterthought, after Hagoromo (a tiny subsatellite deployed by Hiten\nduring a lunar flyby) had a transmitter failure and its proper insertion\ninto lunar orbit couldn't be positively confirmed.\n\nIt should be noted that the technique does have disadvantages.  It takes\na long time, and you end up with a relatively inconvenient lunar orbit.\nIf you want something useful like a low circular polar orbit, you do have\nto plan to expend a certain amount of fuel, although it is reduced from\nwhat you'd need for the brute-force approach.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"# Second-best match.\nprint(corpus.data[top_related_indices[1]])","metadata":{"id":"zQwWXypfR8vh","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:31:06.960754Z","iopub.execute_input":"2025-03-07T03:31:06.961112Z","iopub.status.idle":"2025-03-07T03:31:06.965859Z","shell.execute_reply.started":"2025-03-07T03:31:06.961080Z","shell.execute_reply":"2025-03-07T03:31:06.964861Z"}},"outputs":[{"name":"stdout","text":"\nTheir Hiten engineering-test mission spent a while in a highly eccentric\nEarth orbit doing lunar flybys, and then was inserted into lunar orbit\nusing some very tricky gravity-assist-like maneuvering.  This meant that\nit would crash on the Moon eventually, since there is no such thing as\na stable lunar orbit (as far as anyone knows), and I believe I recall\nhearing recently that it was about to happen.\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"# Try a different query\nquery = [\"satellite\"]\nquery_tfidf = vectorizer.transform(query)\n\ncosine_similarities = cosine_similarity(features, query_tfidf).flatten()\ntop_related_indices = top_k(cosine_similarities, 5)\n\nprint(top_related_indices)\nprint(cosine_similarities[top_related_indices])","metadata":{"id":"w-5aqUbGSM5J","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:31:07.195358Z","iopub.execute_input":"2025-03-07T03:31:07.195670Z","iopub.status.idle":"2025-03-07T03:31:07.208195Z","shell.execute_reply.started":"2025-03-07T03:31:07.195647Z","shell.execute_reply":"2025-03-07T03:31:07.207274Z"}},"outputs":[{"name":"stdout","text":"[378 138 248 539  61]\n[0.39068985 0.34073761 0.29838056 0.26242297 0.25695438]\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"print(corpus.data[top_related_indices[0]])","metadata":{"id":"VHQtRQIcSbTj","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:31:10.125406Z","iopub.execute_input":"2025-03-07T03:31:10.125720Z","iopub.status.idle":"2025-03-07T03:31:10.130781Z","shell.execute_reply.started":"2025-03-07T03:31:10.125694Z","shell.execute_reply":"2025-03-07T03:31:10.129970Z"}},"outputs":[{"name":"stdout","text":"\n\nAs an Amateur Radio operator (VHF 2metres) I like to keep up with what is \ngoing up (and for that matter what is coming down too).\n \nIn about 30 days I have learned ALOT about satellites current, future and \npast all the way back to Vanguard series and up to Astro D observatory \n(space).  I borrowed a book from the library called Weater Satellites (I \nthink, it has a photo of the earth with a TIROS type satellite on it.)\n \nI would like to build a model or have a large color poster of one of the \nTIROS satellites I think there are places in the USA that sell them.\nITOS is my favorite looking satellite, followed by AmSat-OSCAR 13 \n(AO-13).\n \nTTYL\n73\nJim\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"So here we have the beginnings of a simple search engine but we're a far cry from competing with commercial off-the-shelf search engines, let alone Google.\n<br>\n- For each query, we're scanning through our entire corpus, but in practice, you'll want to create an **inverted index**. Search applications such as Elasticsearch do that under the hood.\n- You'd also want to evaluate the efficacy of your search using metrics like **precision** and **recall**.\n- Document ranking also tends to be more sophisticated, using different ranking functions like Okapi BM25. With major search engines, ranking also involves hundreds of variables such as what the user searched for previously, what do they tend to click on, where are they physically, and on and on. These variables are part of the \"secret sauce\" and are closely guarded by companies.\n- Beyond word presence, intent and meaning are playing a larger role.\n<br>\n\nInformation Retrieval is a huge, rich topic and beyond search, it's also key in tasks such as question-answering.","metadata":{"id":"t4v5wQ4JaBIh"}},{"cell_type":"markdown","source":"## TF-IDF Exercises","metadata":{"id":"Ak3LXiETfGIY"}},{"cell_type":"markdown","source":"**EXERCISE**<br>\nRead up on these concepts we just mentioned if you're curious.<br>\n\nhttps://en.wikipedia.org/wiki/Inverted_index<br>\nhttps://en.wikipedia.org/wiki/Precision_and_recall<br>\nhttps://en.wikipedia.org/wiki/Okapi_BM25<br>","metadata":{"id":"08nTQB7_fJU0"}},{"cell_type":"code","source":"#\n# EXERCISE: fetch multiple topics from the 20 newsgroups\n# dataset and query them using the approach we followed.\n# A list of topics can be found here:\n# https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset\n#\n# If you're feeling ambitious, incorporate n-grams or\n# look at how you can measure precision and recall.\n#","metadata":{"id":"Iz2FCCq1fsjz"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1️⃣ Load Multiple Categories from 20 Newsgroups","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import fetch_20newsgroups\n\n# Define categories of interest\ncategories = ['rec.sport.baseball', 'sci.space', 'comp.graphics']\n\n# Load the dataset for selected categories\nnewsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n\n# Print some example data\nprint(\"Categories:\", newsgroups.target_names)\nprint(\"\\nSample Document:\\n\", newsgroups.data[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:34:04.555628Z","iopub.execute_input":"2025-03-07T03:34:04.556003Z","iopub.status.idle":"2025-03-07T03:34:06.039766Z","shell.execute_reply.started":"2025-03-07T03:34:04.555971Z","shell.execute_reply":"2025-03-07T03:34:06.038665Z"}},"outputs":[{"name":"stdout","text":"Categories: ['comp.graphics', 'rec.sport.baseball', 'sci.space']\n\nSample Document:\n \nBy '8 grey level images' you mean 8 items of 1bit images?\nIt does work(!), but it doesn't work if you have more than 1bit\nin your screen and if the screen intensity is non-linear.\n\nWith 2 bit per pixel; there could be 1*c_1 + 4*c_2 timing,\nthis gives 16 levels, but they are linear if screen intensity is\nlinear.\nWith 1*c_1 + 2*c_2 it works, but we have to find the best\ncompinations -- there's 10 levels, but 16 choises; best 10 must be\nchosen. Different compinations for the same level, varies a bit, but\nthe levels keeps their order.\n\nReaders should verify what I wrote... :-)\n","output_type":"stream"}],"execution_count":61},{"cell_type":"markdown","source":"## 2️⃣ Convert Text to Features (TF-IDF)","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))  # Using n-grams\nX = vectorizer.fit_transform(newsgroups.data)\n\nprint(\"Feature Matrix Shape:\", X.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:35:00.425586Z","iopub.execute_input":"2025-03-07T03:35:00.425899Z","iopub.status.idle":"2025-03-07T03:35:01.210161Z","shell.execute_reply.started":"2025-03-07T03:35:00.425873Z","shell.execute_reply":"2025-03-07T03:35:01.208967Z"}},"outputs":[{"name":"stdout","text":"Feature Matrix Shape: (1774, 151017)\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"## 3️⃣ Query the Data","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\nquery = [\"NASA mission to Mars\"]  # Example query\nquery_vec = vectorizer.transform(query)  # Vectorize query\n\n# Compute cosine similarity\nsimilarities = cosine_similarity(query_vec, X)\n\n# Get top 5 most relevant documents\ntop_docs = similarities.argsort()[0][-5:][::-1]\nfor idx in top_docs:\n    print(f\"\\nRelevant Document:\\n{newsgroups.data[idx]}\")\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:37:27.131624Z","iopub.execute_input":"2025-03-07T03:37:27.131960Z","iopub.status.idle":"2025-03-07T03:37:27.148134Z","shell.execute_reply.started":"2025-03-07T03:37:27.131914Z","shell.execute_reply":"2025-03-07T03:37:27.147182Z"}},"outputs":[{"name":"stdout","text":"\nRelevant Document:\nArchive-name: space/probe\nLast-modified: $Date: 93/04/01 14:39:19 $\n\nPLANETARY PROBES - HISTORICAL MISSIONS\n\n    This section was lightly adapted from an original posting by Larry Klaes\n    (klaes@verga.enet.dec.com), mostly minor formatting changes. Matthew\n    Wiener (weemba@libra.wistar.upenn.edu) contributed the section on\n    Voyager, and the section on Sakigake was obtained from ISAS material\n    posted by Yoshiro Yamada (yamada@yscvax.ysc.go.jp).\n\nUS PLANETARY MISSIONS\n\n\n    MARINER (VENUS, MARS, & MERCURY FLYBYS AND ORBITERS)\n\n    MARINER 1, the first U.S. attempt to send a spacecraft to Venus, failed\n    minutes after launch in 1962. The guidance instructions from the ground\n    stopped reaching the rocket due to a problem with its antenna, so the\n    onboard computer took control. However, there turned out to be a bug in\n    the guidance software, and the rocket promptly went off course, so the\n    Range Safety Officer destroyed it. Although the bug is sometimes claimed\n    to have been an incorrect FORTRAN DO statement, it was actually a\n    transcription error in which the bar (indicating smoothing) was omitted\n    from the expression \"R-dot-bar sub n\" (nth smoothed value of derivative\n    of radius). This error led the software to treat normal minor variations\n    of velocity as if they were serious, leading to incorrect compensation.\n\n    MARINER 2 became the first successful probe to flyby Venus in December\n    of 1962, and it returned information which confirmed that Venus is a\n    very hot (800 degrees Fahrenheit, now revised to 900 degrees F.) world\n    with a cloud-covered atmosphere composed primarily of carbon dioxide\n    (sulfuric acid was later confirmed in 1978).\n\n    MARINER 3, launched on November 5, 1964, was lost when its protective\n    shroud failed to eject as the craft was placed into interplanetary\n    space. Unable to collect the Sun's energy for power from its solar\n    panels, the probe soon died when its batteries ran out and is now in\n    solar orbit. It was intended for a Mars flyby with MARINER 4.\n\n    MARINER 4, the sister probe to MARINER 3, did reach Mars in 1965 and\n    took the first close-up images of the Martian surface (22 in all) as it\n    flew by the planet. The probe found a cratered world with an atmosphere\n    much thinner than previously thought. Many scientists concluded from\n    this preliminary scan that Mars was a \"dead\" world in both the\n    geological and biological sense.\n\n    MARINER 5 was sent to Venus in 1967. It reconfirmed the data on that\n    planet collected five years earlier by MARINER 2, plus the information\n    that Venus' atmospheric pressure at its surface is at least 90 times\n    that of Earth's, or the equivalent of being 3,300 feet under the surface\n    of an ocean.\n\n    MARINER 6 and 7 were sent to Mars in 1969 and expanded upon the work\n    done by MARINER 4 four years earlier. However, they failed to take away\n    the concept of Mars as a \"dead\" planet, first made from the basic\n    measurements of MARINER 4.\n\n    MARINER 8 ended up in the Atlantic Ocean in 1971 when the rocket\n    launcher autopilot failed.\n\n    MARINER 9, the sister probe to MARINER 8, became the first craft to\n    orbit Mars in 1971. It returned information on the Red Planet that no\n    other probe had done before, revealing huge volcanoes on the Martian\n    surface, as well as giant canyon systems, and evidence that water once\n    flowed across the planet. The probe also took the first detailed closeup\n    images of Mars' two small moons, Phobos and Deimos.\n\n    MARINER 10 used Venus as a gravity assist to Mercury in 1974. The probe\n    did return the first close-up images of the Venusian atmosphere in\n    ultraviolet, revealing previously unseen details in the cloud cover,\n    plus the fact that the entire cloud system circles the planet in four\n    Earth days. MARINER 10 eventually made three flybys of Mercury from 1974\n    to 1975 before running out of attitude control gas. The probe revealed\n    Mercury as a heavily cratered world with a mass much greater than\n    thought. This would seem to indicate that Mercury has an iron core which\n    makes up 75 percent of the entire planet.\n\n\n    PIONEER (MOON, SUN, VENUS, JUPITER, and SATURN FLYBYS AND ORBITERS)\n\n    PIONEER 1 through 3 failed to meet their main objective - to photograph\n    the Moon close-up - but they did reach far enough into space to provide\n    new information on the area between Earth and the Moon, including new\n    data on the Van Allen radiation belts circling Earth. All three craft\n    had failures with their rocket launchers. PIONEER 1 was launched on\n    October 11, 1958, PIONEER 2 on November 8, and PIONEER 3 on December 6.\n\n    PIONEER 4 was a Moon probe which missed the Moon and became the first\n    U.S. spacecraft to orbit the Sun in 1959. PIONEER 5 was originally\n    designed to flyby Venus, but the mission was scaled down and it instead\n    studied the interplanetary environment between Venus and Earth out to\n    36.2 million kilometers in 1960, a record until MARINER 2. PIONEER 6\n    through 9 were placed into solar orbit from 1965 to 1968: PIONEER 6, 7,\n    and 8 are still transmitting information at this time. PIONEER E (would\n    have been number 10) suffered a launch failure in 1969.\n\n    PIONEER 10 became the first spacecraft to flyby Jupiter in 1973. PIONEER\n    11 followed it in 1974, and then went on to become the first probe to\n    study Saturn in 1979. Both vehicles should continue to function through\n    1995 and are heading off into interstellar space, the first craft ever\n    to do so.\n\n    PIONEER Venus 1 (1978) (also known as PIONEER Venus Orbiter, or PIONEER\n    12) burned up in the Venusian atmosphere on October 8, 1992. PVO made\n    the first radar studies of the planet's surface via probe. PIONEER Venus\n    2 (also known as PIONEER 13) sent four small probes into the atmosphere\n    in December of 1978. The main spacecraft bus burned up high in the\n    atmosphere, while the four probes descended by parachute towards the\n    surface. Though none were expected to survive to the surface, the Day\n    probe did make it and transmitted for 67.5 minutes on the ground before\n    its batteries failed.\n\n\n    RANGER (LUNAR LANDER AND IMPACT MISSIONS)\n\n    RANGER 1 and 2 were test probes for the RANGER lunar impact series. They\n    were meant for high Earth orbit testing in 1961, but rocket problems\n    left them in useless low orbits which quickly decayed.\n\n    RANGER 3, launched on January 26, 1962, was intended to land an\n    instrument capsule on the surface of the Moon, but problems during the\n    launch caused the probe to miss the Moon and head into solar orbit.\n    RANGER 3 did try to take some images of the Moon as it flew by, but the\n    camera was unfortunately aimed at deep space during the attempt.\n\n    RANGER 4, launched April 23, 1962, had the same purpose as RANGER 3, but\n    suffered technical problems enroute and crashed on the lunar farside,\n    the first U.S. probe to reach the Moon, albeit without returning data.\n\n    RANGER 5, launched October 18, 1962 and similar to RANGER 3 and 4, lost\n    all solar panel and battery power enroute and eventually missed the Moon\n    and drifted off into solar orbit.\n\n    RANGER 6 through 9 had more modified lunar missions: They were to send\n    back live images of the lunar surface as they headed towards an impact\n    with the Moon. RANGER 6 failed this objective in 1964 when its cameras\n    did not operate. RANGER 7 through 9 performed well, becoming the first\n    U.S. lunar probes to return thousands of lunar images through 1965.\n\n\n    LUNAR ORBITER (LUNAR SURFACE PHOTOGRAPHY)\n\n    LUNAR ORBITER 1 through 5 were designed to orbit the Moon and image\n    various sites being studied as landing areas for the manned APOLLO\n    missions of 1969-1972. The probes also contributed greatly to our\n    understanding of lunar surface features, particularly the lunar farside.\n    All five probes of the series, launched from 1966 to 1967, were\n    essentially successful in their missions. They were the first U.S.\n    probes to orbit the Moon. All LOs were eventually crashed into the lunar\n    surface to avoid interference with the manned APOLLO missions.\n\n\n    SURVEYOR (LUNAR SOFT LANDERS)\n\n    The SURVEYOR series were designed primarily to see if an APOLLO lunar\n    module could land on the surface of the Moon without sinking into the\n    soil (before this time, it was feared by some that the Moon was covered\n    in great layers of dust, which would not support a heavy landing\n    vehicle). SURVEYOR was successful in proving that the lunar surface was\n    strong enough to hold up a spacecraft from 1966 to 1968.\n\n    Only SURVEYOR 2 and 4 were unsuccessful missions. The rest became the\n    first U.S. probes to soft land on the Moon, taking thousands of images\n    and scooping the soil for analysis. APOLLO 12 landed 600 feet from\n    SURVEYOR 3 in 1969 and returned parts of the craft to Earth. SURVEYOR 7,\n    the last of the series, was a purely scientific mission which explored\n    the Tycho crater region in 1968.\n\n\n    VIKING (MARS ORBITERS AND LANDERS)\n\n    VIKING 1 was launched from Cape Canaveral, Florida on August 20, 1975 on\n    a TITAN 3E-CENTAUR D1 rocket. The probe went into Martian orbit on June\n    19, 1976, and the lander set down on the western slopes of Chryse\n    Planitia on July 20, 1976. It soon began its programmed search for\n    Martian micro-organisms (there is still debate as to whether the probes\n    found life there or not), and sent back incredible color panoramas of\n    its surroundings. One thing scientists learned was that Mars' sky was\n    pinkish in color, not dark blue as they originally thought (the sky is\n    pink due to sunlight reflecting off the reddish dust particles in the\n    thin atmosphere). The lander set down among a field of red sand and\n    boulders stretching out as far as its cameras could image.\n\n    The VIKING 1 orbiter kept functioning until August 7, 1980, when it ran\n    out of attitude-control propellant. The lander was switched into a\n    weather-reporting mode, where it had been hoped it would keep\n    functioning through 1994; but after November 13, 1982, an errant command\n    had been sent to the lander accidentally telling it to shut down until\n    further orders. Communication was never regained again, despite the\n    engineers' efforts through May of 1983.\n\n    An interesting side note: VIKING 1's lander has been designated the\n    Thomas A. Mutch Memorial Station in honor of the late leader of the\n    lander imaging team. The National Air and Space Museum in Washington,\n    D.C. is entrusted with the safekeeping of the Mutch Station Plaque until\n    it can be attached to the lander by a manned expedition.\n\n    VIKING 2 was launched on September 9, 1975, and arrived in Martian orbit\n    on August 7, 1976. The lander touched down on September 3, 1976 in\n    Utopia Planitia. It accomplished essentially the same tasks as its\n    sister lander, with the exception that its seisometer worked, recording\n    one marsquake. The orbiter had a series of attitude-control gas leaks in\n    1978, which prompted it being shut down that July. The lander was shut\n    down on April 12, 1980.\n\n    The orbits of both VIKING orbiters should decay around 2025.\n\n\n    VOYAGER (OUTER PLANET FLYBYS)\n\n    VOYAGER 1 was launched September 5, 1977, and flew past Jupiter on March\n    5, 1979 and by Saturn on November 13, 1980. VOYAGER 2 was launched\n    August 20, 1977 (before VOYAGER 1), and flew by Jupiter on August 7,\n    1979, by Saturn on August 26, 1981, by Uranus on January 24, 1986, and\n    by Neptune on August 8, 1989. VOYAGER 2 took advantage of a rare\n    once-every-189-years alignment to slingshot its way from outer planet to\n    outer planet. VOYAGER 1 could, in principle, have headed towards Pluto,\n    but JPL opted for the sure thing of a Titan close up.\n\n    Between the two probes, our knowledge of the 4 giant planets, their\n    satellites, and their rings has become immense. VOYAGER 1&2 discovered\n    that Jupiter has complicated atmospheric dynamics, lightning and\n    aurorae. Three new satellites were discovered. Two of the major\n    surprises were that Jupiter has rings and that Io has active sulfurous\n    volcanoes, with major effects on the Jovian magnetosphere.\n\n    When the two probes reached Saturn, they discovered over 1000 ringlets\n    and 7 satellites, including the predicted shepherd satellites that keep\n    the rings stable. The weather was tame compared with Jupiter: massive\n    jet streams with minimal variance (a 33-year great white spot/band cycle\n    is known). Titan's atmosphere was smoggy. Mimas' appearance was\n    startling: one massive impact crater gave it the Death Star appearance.\n    The big surprise here was the stranger aspects of the rings. Braids,\n    kinks, and spokes were both unexpected and difficult to explain.\n\n    VOYAGER 2, thanks to heroic engineering and programming efforts,\n    continued the mission to Uranus and Neptune. Uranus itself was highly\n    monochromatic in appearance. One oddity was that its magnetic axis was\n    found to be highly skewed from the already completely skewed rotational\n    axis, giving Uranus a peculiar magnetosphere. Icy channels were found on\n    Ariel, and Miranda was a bizarre patchwork of different terrains. 10\n    satellites and one more ring were discovered.\n\n    In contrast to Uranus, Neptune was found to have rather active weather,\n    including numerous cloud features. The ring arcs turned out to be bright\n    patches on one ring. Two other rings, and 6 other satellites, were\n    discovered. Neptune's magnetic axis was also skewed. Triton had a\n    canteloupe appearance and geysers. (What's liquid at 38K?)\n\n    The two VOYAGERs are expected to last for about two more decades. Their\n    on-target journeying gives negative evidence about possible planets\n    beyond Pluto. Their next major scientific discovery should be the\n    location of the heliopause.\n\n\nSOVIET PLANETARY MISSIONS\n\n    Since there have been so many Soviet probes to the Moon, Venus, and\n    Mars, I will highlight only the primary missions:\n\n\n    SOVIET LUNAR PROBES\n\n    LUNA 1 - Lunar impact attempt in 1959, missed Moon and became first\n\t     craft in solar orbit.\n    LUNA 2 - First craft to impact on lunar surface in 1959.\n    LUNA 3 - Took first images of lunar farside in 1959.\n    ZOND 3 - Took first images of lunar farside in 1965 since LUNA 3. Was\n\t     also a test for future Mars missions.\n    LUNA 9 - First probe to soft land on the Moon in 1966, returned images\n\t     from surface.\n    LUNA 10 - First probe to orbit the Moon in 1966.\n    LUNA 13 - Second successful Soviet lunar soft landing mission in 1966.\n    ZOND 5 - First successful circumlunar craft. ZOND 6 through 8\n\t     accomplished similar missions through 1970. The probes were\n\t     unmanned tests of a manned orbiting SOYUZ-type lunar vehicle.\n    LUNA 16 - First probe to land on Moon and return samples of lunar soil\n\t      to Earth in 1970. LUNA 20 accomplished similar mission in\n\t      1972.\n    LUNA 17 - Delivered the first unmanned lunar rover to the Moon's\n\t      surface, LUNOKHOD 1, in 1970. A similar feat was accomplished\n\t      with LUNA 21/LUNOKHOD 2 in 1973.\n    LUNA 24 - Last Soviet lunar mission to date. Returned soil samples in\n\t      1976.\n\n\n    SOVIET VENUS PROBES\n\n    VENERA 1 - First acknowledged attempt at Venus mission. Transmissions\n\t       lost enroute in 1961.\n    VENERA 2 - Attempt to image Venus during flyby mission in tandem with\n\t       VENERA 3. Probe ceased transmitting just before encounter in\n\t       February of 1966. No images were returned.\n    VENERA 3 - Attempt to place a lander capsule on Venusian surface.\n\t       Transmissions ceased just before encounter and entire probe\n\t       became the first craft to impact on another planet in 1966.\n    VENERA 4 - First probe to successfully return data while descending\n\t       through Venusian atmosphere. Crushed by air pressure before\n\t       reaching surface in 1967. VENERA 5 and 6 mission profiles\n\t       similar in 1969.\n    VENERA 7 - First probe to return data from the surface of another planet\n\t       in 1970. VENERA 8 accomplished a more detailed mission in\n\t       1972.\n    VENERA 9 - Sent first image of Venusian surface in 1975. Was also the\n\t       first probe to orbit Venus. VENERA 10 accomplished similar\n\t       mission.\n    VENERA 13 - Returned first color images of Venusian surface in 1982.\n\t\tVENERA 14 accomplished similar mission.\n    VENERA 15 - Accomplished radar mapping with VENERA 16 of sections of\n\t\tplanet's surface in 1983 more detailed than PVO.\n    VEGA 1 - Accomplished with VEGA 2 first balloon probes of Venusian\n\t     atmosphere in 1985, including two landers. Flyby buses went on\n\t     to become first spacecraft to study Comet Halley close-up in\n\t     March of 1986.\n\n\n    SOVIET MARS PROBES\n\n    MARS 1 - First acknowledged Mars probe in 1962. Transmissions ceased\n\t     enroute the following year.\n    ZOND 2 - First possible attempt to place a lander capsule on Martian\n\t     surface. Probe signals ceased enroute in 1965.\n    MARS 2 - First Soviet Mars probe to land - albeit crash - on Martian\n\t     surface. Orbiter section first Soviet probe to circle the Red\n\t     Planet in 1971.\n    MARS 3 - First successful soft landing on Martian surface, but lander\n\t     signals ceased after 90 seconds in 1971.\n    MARS 4 - Attempt at orbiting Mars in 1974, braking rockets failed to\n\t     fire, probe went on into solar orbit.\n    MARS 5 - First fully successful Soviet Mars mission, orbiting Mars in\n\t     1974. Returned images of Martian surface comparable to U.S.\n\t     probe MARINER 9.\n    MARS 6 - Landing attempt in 1974. Lander crashed into the surface.\n    MARS 7 - Lander missed Mars completely in 1974, went into a solar orbit\n\t     with its flyby bus.\n    PHOBOS 1 - First attempt to land probes on surface of Mars' largest\n\t       moon, Phobos. Probe failed enroute in 1988 due to\n\t       human/computer error.\n    PHOBOS 2 - Attempt to land probes on Martian moon Phobos. The probe did\n\t       enter Mars orbit in early 1989, but signals ceased one week\n\t       before scheduled Phobos landing.\n\n    While there has been talk of Soviet Jupiter, Saturn, and even\n    interstellar probes within the next thirty years, no major steps have\n    yet been taken with these projects. More intensive studies of the Moon,\n    Mars, Venus, and various comets have been planned for the 1990s, and a\n    Mercury mission to orbit and land probes on the tiny world has been\n    planned for 2003. How the many changes in the former Soviet Union (now\n    the Commonwealth of Independent States) will affect the future of their\n    space program remains to be seen.\n\n\nJAPANESE PLANETARY MISSIONS\n\n    SAKIGAKE (MS-T5) was launched from the Kagoshima Space Center by ISAS on\n    January 8 1985, and approached Halley's Comet within about 7 million km\n    on March 11, 1986. The spacecraft is carrying three instru- ments to\n    measure interplanetary magnetic field/plasma waves/solar wind, all of\n    which work normally now, so ISAS made an Earth swingby by Sakigake on\n    January 8, 1992 into an orbit similar to the earth's. The closest\n    approach was at 23h08m47s (JST=UTC+9h) on January 8, 1992. The\n    geocentric distance was 88,997 km. This is the first planet-swingby for\n    a Japanese spacecraft.\n\n    During the approach, Sakigake observed the geotail. Some geotail\n    passages will be scheduled in some years hence. The second Earth-swingby\n    will be on June 14, 1993 (at 40 Re (Earth's radius)), and the third\n    October 28, 1994 (at 86 Re).\n\n\n    HITEN, a small lunar probe, was launched into Earth orbit on January 24,\n    1990. The spacecraft was then known as MUSES-A, but was renamed to Hiten\n    once in orbit. The 430 lb probe looped out from Earth and made its first\n    lunary flyby on March 19, where it dropped off its 26 lb midget\n    satellite, HAGOROMO. Japan at this point became the third nation to\n    orbit a satellite around the Moon, joining the Unites States and USSR.\n\n    The smaller spacecraft, Hagoromo, remained in orbit around the Moon. An\n    apparently broken transistor radio caused the Japanese space scientists\n    to lose track of it. Hagoromo's rocket motor fired on schedule on March\n    19, but the spacecraft's tracking transmitter failed immediately. The\n    rocket firing of Hagoromo was optically confirmed using the Schmidt\n    camera (105-cm, F3.1) at the Kiso Observatory in Japan.\n\n    Hiten made multiple lunar flybys at approximately monthly intervals and\n    performed aerobraking experiments using the Earth's atmosphere. Hiten\n    made a close approach to the moon at 22:33 JST (UTC+9h) on February 15,\n    1992 at the height of 423 km from the moon's surface (35.3N, 9.7E) and\n    fired its propulsion system for about ten minutes to put the craft into\n    lunar orbit. The following is the orbital calculation results after the\n    approach:\n\n\tApoapsis Altitude: about 49,400 km\n\tPeriapsis Altitude: about 9,600 km\n\tInclination\t: 34.7 deg (to ecliptic plane)\n\tPeriod\t\t: 4.7 days\n\n\nPLANETARY MISSION REFERENCES\n\n    I also recommend reading the following works, categorized in three\n    groups: General overviews, specific books on particular space missions,\n    and periodical sources on space probes. This list is by no means\n    complete; it is primarily designed to give you places to start your\n    research through generally available works on the subject. If anyone can\n    add pertinent works to the list, it would be greatly appreciated.\n\n    Though naturally I recommend all the books listed below, I think it\n    would be best if you started out with the general overview books, in\n    order to give you a clear idea of the history of space exploration in\n    this area. I also recommend that you pick up some good, up-to-date\n    general works on astronomy and the Sol system, to give you some extra\n    background. Most of these books and periodicals can be found in any good\n    public and university library. Some of the more recently published works\n    can also be purchased in and/or ordered through any good mass- market\n    bookstore.\n\n    General Overviews (in alphabetical order by author):\n\n      J. Kelly Beatty et al, THE NEW SOLAR SYSTEM, 1990.\n\n      Merton E. Davies and Bruce C. Murray, THE VIEW FROM SPACE:\n       PHOTOGRAPHIC EXPLORATION OF THE PLANETS, 1971\n\n      Kenneth Gatland, THE ILLUSTRATED ENCYCLOPEDIA OF SPACE\n       TECHNOLOGY, 1990\n\n      Kenneth Gatland, ROBOT EXPLORERS, 1972\n\n      R. Greeley, PLANETARY LANDSCAPES, 1987\n\n      Douglas Hart, THE ENCYCLOPEDIA OF SOVIET SPACECRAFT, 1987\n\n      Nicholas L. Johnson, HANDBOOK OF SOVIET LUNAR AND PLANETARY\n       EXPLORATION, 1979\n\n      Clayton R. Koppes, JPL AND THE AMERICAN SPACE PROGRAM: A\n       HISTORY OF THE JET PROPULSION LABORATORY, 1982\n\n      Richard S. Lewis, THE ILLUSTRATED ENCYCLOPEDIA OF THE\n       UNIVERSE, 1983\n\n      Mark Littman, PLANETS BEYOND: DISCOVERING THE OUTER SOLAR\n       SYSTEM, 1988\n\n      Eugene F. Mallove and Gregory L. Matloff, THE STARFLIGHT\n       HANDBOOK: A PIONEER'S GUIDE TO INTERSTELLAR TRAVEL, 1989\n\n      Frank Miles and Nicholas Booth, RACE TO MARS: THE MARS\n       FLIGHT ATLAS, 1988\n\n      Bruce Murray, JOURNEY INTO SPACE, 1989\n\n      Oran W. Nicks, FAR TRAVELERS, 1985 (NASA SP-480)\n\n      James E. Oberg, UNCOVERING SOVIET DISASTERS: EXPLORING THE\n       LIMITS OF GLASNOST, 1988\n\n      Carl Sagan, COMET, 1986\n\n      Carl Sagan, THE COSMIC CONNECTION, 1973\n\n      Carl Sagan, PLANETS, 1969 (LIFE Science Library)\n\n      Arthur Smith, PLANETARY EXPLORATION: THIRTY YEARS OF UNMANNED\n       SPACE PROBES, 1988\n\n      Andrew Wilson, (JANE'S) SOLAR SYSTEM LOG, 1987\n\n    Specific Mission References:\n\n      Charles A. Cross and Patrick Moore, THE ATLAS OF MERCURY, 1977\n       (The MARINER 10 mission to Venus and Mercury, 1973-1975)\n\n      Joel Davis, FLYBY: THE INTERPLANETARY ODYSSEY OF VOYAGER 2, 1987\n\n      Irl Newlan, FIRST TO VENUS: THE STORY OF MARINER 2, 1963\n\n      Margaret Poynter and Arthur L. Lane, VOYAGER: THE STORY OF A\n       SPACE MISSION, 1984\n\n      Carl Sagan, MURMURS OF EARTH, 1978 (Deals with the Earth\n       information records placed on VOYAGER 1 and 2 in case the\n       probes are found by intelligences in interstellar space,\n       as well as the probes and planetary mission objectives\n       themselves.)\n\n    Other works and periodicals:\n\n    NASA has published very detailed and technical books on every space\n    probe mission it has launched. Good university libraries will carry\n    these books, and they are easily found simply by knowing which mission\n    you wish to read about. I recommend these works after you first study\n    some of the books listed above.\n\n    Some periodicals I recommend for reading on space probes are NATIONAL\n    GEOGRAPHIC, which has written articles on the PIONEER probes to Earth's\n    Moon Luna and the Jovian planets Jupiter and Saturn, the RANGER,\n    SURVEYOR, LUNAR ORBITER, and APOLLO missions to Luna, the MARINER\n    missions to Mercury, Venus, and Mars, the VIKING probes to Mars, and the\n    VOYAGER missions to Jupiter, Saturn, Uranus, and Neptune.\n\n    More details on American, Soviet, European, and Japanese probe missions\n    can be found in SKY AND TELESCOPE, ASTRONOMY, SCIENCE, NATURE, and\n    SCIENTIFIC AMERICAN magazines. TIME, NEWSWEEK, and various major\n    newspapers can supply not only general information on certain missions,\n    but also show you what else was going on with Earth at the time events\n    were unfolding, if that is of interest to you. Space missions are\n    affected by numerous political, economic, and climatic factors, as you\n    probably know.\n\n    Depending on just how far your interest in space probes will go, you\n    might also wish to join The Planetary Society, one of the largest space\n    groups in the world dedicated to planetary exploration. Their\n    periodical, THE PLANETARY REPORT, details the latest space probe\n    missions. Write to The Planetary Society, 65 North Catalina Avenue,\n    Pasadena, California 91106 USA.\n\n    Good luck with your studies in this area of space exploration. I\n    personally find planetary missions to be one of the more exciting areas\n    in this field, and the benefits human society has and will receive from\n    it are incredible, with many yet to be realized.\n\n    Larry Klaes  klaes@verga.enet.dec.com\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"## 4️⃣ Measure Precision & Recall\n\nTo evaluate the performance of classification models, you can compute:\n\n- Precision (How many retrieved documents are relevant?)\n- Recall (How many relevant documents were retrieved?)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import precision_score, recall_score\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(X, newsgroups.target, test_size=0.2, random_state=42)\n\n# Train a classifier\nclf = MultinomialNB()\nclf.fit(X_train, y_train)\n\n# Predict on test set\ny_pred = clf.predict(X_test)\n\n# Compute Precision & Recall\nprecision = precision_score(y_test, y_pred, average='weighted')\nrecall = recall_score(y_test, y_pred, average='weighted')\n\nprint(f\"Precision: {precision:.2f}\")\nprint(f\"Recall: {recall:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:39:38.209564Z","iopub.execute_input":"2025-03-07T03:39:38.209907Z","iopub.status.idle":"2025-03-07T03:39:38.258966Z","shell.execute_reply.started":"2025-03-07T03:39:38.209877Z","shell.execute_reply":"2025-03-07T03:39:38.258109Z"}},"outputs":[{"name":"stdout","text":"Precision: 0.94\nRecall: 0.94\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"newsgroups.target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:41:01.955787Z","iopub.execute_input":"2025-03-07T03:41:01.956140Z","iopub.status.idle":"2025-03-07T03:41:01.961541Z","shell.execute_reply.started":"2025-03-07T03:41:01.956110Z","shell.execute_reply":"2025-03-07T03:41:01.960534Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 1, ..., 2, 1, 1])"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"newsgroups.target_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:41:27.715037Z","iopub.execute_input":"2025-03-07T03:41:27.715387Z","iopub.status.idle":"2025-03-07T03:41:27.720974Z","shell.execute_reply.started":"2025-03-07T03:41:27.715358Z","shell.execute_reply":"2025-03-07T03:41:27.720033Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"['comp.graphics', 'rec.sport.baseball', 'sci.space']"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}